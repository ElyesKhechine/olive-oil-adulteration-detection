# -*- coding: utf-8 -*-
"""TP1 ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uOr4b06teZA64OWD-EKpWr7GyUbkHlHJ
"""

!pip install liac-arff

# Importation des bibliothèques nécessaires
import urllib.request
import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.gaussian_process.kernels import RBF
import arff

# Téléchargement du fichier OliveOil_TRAIN.arff depuis le site http://www.timeseriesclassification.com/
# et enregistrement sous le nom OliveOil.zip

urllib.request.urlretrieve("http://www.timeseriesclassification.com/Downloads/OliveOil.zip", "OliveOil.zip")

# Décompression du fichier OliveOil.zip
!unzip OliveOil.zip

# Chargement du fichier ARFF contenant les données d'entraînement
with open('OliveOil_TRAIN.arff') as f:
    dataset = arff.load(f)

# Extraction des données et des métadonnées
data = np.array(dataset['data'], dtype=np.float64)
meta = dataset['attributes']

# Séparation des données en features (X) et labels (y)
X = data[:,:-1]
y = data[:,-1]

# Définition des différents classificateurs à tester
classifiers = [
    ("Naive Bayes", GaussianNB()),
    
    ("K-Nearest Neighbors (DEFAULT K=5)", KNeighborsClassifier()),
    ("K-Nearest Neighbors (K=3)", KNeighborsClassifier(3)),

    ("Linear Discriminant Analysis", LinearDiscriminantAnalysis()),

    ("Decision Tree", DecisionTreeClassifier()),
    ("Decision Tree (max_depth=4)", DecisionTreeClassifier(max_depth=4)),

    ("Artificial Neural Networks (DEFAULT: alpha=0.0001 max_iter=200) ", MLPClassifier()),
    ("Artificial Neural Networks (alpha=0.0000000001, max_iter=1000)", MLPClassifier(alpha=0.0000000001, max_iter=1000)),

    ("RBF SVM (DEFAULT gamma='scale', C=1)", SVC()),
    ("RBF SVM (gamma=15, C=4)", SVC(gamma=15, C=3)),

    ("Linear SVM (DEFAULT gamma='scale', C=1)", SVC(kernel="linear")),
    ("Linear SVM (gamma=15, C=25)", SVC(kernel="linear", gamma=15, C=25)),

    ("Poly SVM (DEFAULT gamma='scale', C=1)", SVC(kernel="poly")),
    ("Poly SVM (gamma=15, C=3)", SVC(kernel="poly", gamma=15, C=3)),

    ("Sigmoid SVM", SVC(kernel="sigmoid")),
    ("Gaussian Process", GaussianProcessClassifier(1.0 * RBF(1.0))),
    ("Random Forest", RandomForestClassifier(max_depth=5, n_estimators=10, max_features=570)),
    ("AdaBoost", AdaBoostClassifier()),
    ("QDA", QuadraticDiscriminantAnalysis())    
]

# Entrainement de chaque classificateur et affichage des résultats
max_accuracy = 0  # Initialisation de la variable contenant la précision maximale obtenue
for name, model in classifiers:
    model.fit(X, y)  # Entraînement du modèle avec les données d'entraînement
    
    # Chargement du fichier ARFF contenant les données de test pour l'évaluation des performances des classificateurs
    with open('OliveOil_TEST.arff') as f:
        test_data = arff.load(f)['data']
    X_test = np.array(test_data, dtype=np.float64)[:,:-1]
    y_test = np.array(test_data, dtype=np.float64)[:,-1]

    # Utilisation du modèle entraîné pour prédire les labels des données de test
    y_pred = model.predict(X_test)

    # Calcul de la précision du modèle
    accuracy = accuracy_score(y_test, y_pred)
    if accuracy > max_accuracy:
        max_accuracy = accuracy
    
    # Affichage d'un graphe montrant les labels prédits par rapport aux labels réels pour chaque classe
    colors = ['blue', 'red', 'green', 'orange']
    labels = ['class 1', 'class 2', 'class 3', 'class 4']
    for i in range(4):
        plt.scatter(y_test[y_test==i+1], y_pred[y_test==i+1], color=colors[i], label=labels[i])
    plt.xlabel("Classe réelle")
    plt.ylabel("Classe prédite")
    plt.title(name + " - Résultats du classificateur\nPrécision : {:.2f}%".format(accuracy * 100))
    plt.legend()
    plt.show()